{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK17XhUgwwam"
      },
      "source": [
        "# Installing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aljJe_OKuuqr"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c04kTlIlwz93"
      },
      "source": [
        "# Importing required libraries\n",
        "\n",
        "The required libraries are:\n",
        "- *Pandas*     :       for handling the dataframes\n",
        "- *Numpy*      :       for handling the arrays\n",
        "- *Tensorflow* :       for making the neural network model\n",
        "- *Matplotlib* :       for visualizing the features extracted from audio data\n",
        "- *Ipython*    :       for handling audio files  \n",
        "- *Jiwer*      :       to compute the word error rate of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rqovnJwu3R6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers #type:ignore\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbJ9YC0qw4md"
      },
      "source": [
        "# Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAHAZxfRHTrD"
      },
      "outputs": [],
      "source": [
        "data_url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
        "data_path = keras.utils.get_file(\"LJSpeech-1.1\", data_url, untar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_xo6mzwvWH_"
      },
      "outputs": [],
      "source": [
        "wavs_path = data_path + \"/wavs/\"\n",
        "metadata_path = data_path + \"/metadata.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NJ0e4VZNbkw"
      },
      "outputs": [],
      "source": [
        "metadata_df = pd.read_csv(metadata_path, header=None, quoting=3, sep=\"|\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mwPWg41jzxWa"
      },
      "outputs": [],
      "source": [
        "metadata_df.columns = [ 'file_name', 'transcription',  'normalized_trancription']\n",
        "metadata_df = metadata_df[['file_name', 'normalized_trancription']]\n",
        "metadata_df = metadata_df.sample(frac = 1).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5kFivB1r800"
      },
      "source": [
        "## *NOTE: I am training my model only on 5000 datapoints*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--a6jnw8raAC"
      },
      "outputs": [],
      "source": [
        "metadata_df = metadata_df[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5Y6amJ0z2n"
      },
      "source": [
        "# Train Test Split\n",
        "\n",
        "The train val split ratio is *0.9*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtEOVv8I0Vg-"
      },
      "outputs": [],
      "source": [
        "df_train = metadata_df[:int(len(metadata_df) * 0.9)]\n",
        "df_val = metadata_df[int(len(metadata_df) * 0.9):]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bvt7nKB05rb"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q0V6z9X08vY"
      },
      "source": [
        "### Making the vocabulary to be used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwF7Qt6t06_K"
      },
      "outputs": [],
      "source": [
        "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"] # Set of all characters\n",
        "char_to_num = keras.layers.StringLookup(vocabulary = characters, oov_token = \"\") # Mapping chars to nums\n",
        "num_to_char = keras.layers.StringLookup(vocabulary = char_to_num.get_vocabulary(), oov_token = \"\", invert = True) # Mapping nums to chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT34R6Za1k-6"
      },
      "outputs": [],
      "source": [
        "frame_length = 256\n",
        "frame_step = 160\n",
        "fft_length = 384"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzTQ770F2SEV"
      },
      "outputs": [],
      "source": [
        "def encode_single_sample(wav_file, label):\n",
        "\n",
        "    # Read the wav file\n",
        "    file = tf.io.read_file(wavs_path + wav_file + \".wav\")\n",
        "\n",
        "    # Decode the wav file\n",
        "    audio, _ = tf.audio.decode_wav(file)\n",
        "    audio = tf.squeeze(audio, axis = -1)\n",
        "\n",
        "    # Change type to float\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "\n",
        "    # Get the spectrogram\n",
        "    spectrogram = tf.signal.stft(audio, frame_length = frame_length, frame_step = frame_step, fft_length = fft_length)\n",
        "\n",
        "    # Get the magnitude\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "\n",
        "    # Normalize\n",
        "    means = tf.math.reduce_mean(spectrogram, 1, keepdims = True)\n",
        "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims = True)\n",
        "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "    # Get the label\n",
        "    label = tf.strings.lower(label)\n",
        "    label = tf.strings.unicode_split(label, input_encoding = \"UTF-8\")\n",
        "    label = char_to_num(label)\n",
        "\n",
        "    return spectrogram, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3L6QqVP3uE4"
      },
      "source": [
        "# Creating dataset object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2i6IJ0Ws3tXJ"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Training dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((list(df_train['file_name']), list(df_train['normalized_trancription'])))\n",
        "train_dataset = train_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n",
        "# Validation dataset\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((list(df_val['file_name']), list(df_val['normalized_trancription'])))\n",
        "val_dataset = val_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPv8wst66DUV"
      },
      "source": [
        "# Defining loss function\n",
        "\n",
        "The loss function used here is CTC loss function, which is widely used in speech recognition purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdEHNzzN5A8y"
      },
      "outputs": [],
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype = \"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype = \"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype = \"int64\")\n",
        "    input_length = input_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n",
        "    label_length = label_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n",
        "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfpMiC096SsD"
      },
      "source": [
        "# Making the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX-dxivp6PQe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
        "\n",
        "    # Input layer\n",
        "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
        "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
        "\n",
        "    # Conv layer 1\n",
        "    x = layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 41],\n",
        "        strides=[2, 2],\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"conv_1\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
        "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
        "\n",
        "    # Conv layer 2\n",
        "    x = layers.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=[11, 21],\n",
        "        strides=[1, 2],\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"conv_2\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
        "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
        "\n",
        "    # Reshape\n",
        "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]), name=\"reshape_1\")(x)\n",
        "\n",
        "    # RNN layers\n",
        "    for i in range(0, 3):\n",
        "        recurrent = layers.GRU(\n",
        "            units=rnn_units,\n",
        "            activation=\"tanh\",\n",
        "            recurrent_activation=\"sigmoid\",\n",
        "            use_bias=True,\n",
        "            return_sequences=True,\n",
        "            reset_after=True,\n",
        "            name=f\"gru_{i}\"\n",
        "        )\n",
        "        x = layers.Bidirectional(\n",
        "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
        "        )(x)\n",
        "        if i < rnn_layers:\n",
        "            x = layers.Dropout(rate=0.5, name=f\"dropout_{i}\")(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = layers.Dense(units=rnn_units, name=\"dense_1\")(x)\n",
        "    x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
        "    x = layers.Dropout(rate=0.5, name=\"dropout_final\")(x)\n",
        "\n",
        "    # Classification layer\n",
        "    output = layers.Dense(units=output_dim + 1, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "    # Model\n",
        "    model = models.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
        "\n",
        "    # Optimizer\n",
        "    opt = optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=opt, loss=\"CTC\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk_Jz4JX8Q6E"
      },
      "outputs": [],
      "source": [
        "model = build_model(\n",
        "    input_dim = fft_length // 2 + 1,\n",
        "    output_dim = char_to_num.vocabulary_size(),\n",
        "    rnn_units = 512,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HkeQMwD8XOK"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp7D22r78fml"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcC5tm_28ZMm"
      },
      "outputs": [],
      "source": [
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results = keras.backend.ctc_decode(pred, input_length = input_len, greedy = True)[0][0]\n",
        "    output_text = []\n",
        "    for result in results:\n",
        "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(result)\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUPfmgT282bT"
      },
      "outputs": [],
      "source": [
        "class CustomCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs = None):\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        for batch in self.dataset:\n",
        "            X, y = batch\n",
        "            batch_predictions = model.predict(X)\n",
        "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "            predictions.extend(batch_predictions)\n",
        "            for label in y:\n",
        "                label = (\n",
        "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "                )\n",
        "                targets.append(label)\n",
        "\n",
        "        wer_score = wer(targets, predictions)\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "        print(\"-\" * 100)\n",
        "        for i in np.random.randint(0, len(predictions), 2):\n",
        "            print(f\"Target    : {targets[i]}\")\n",
        "            print(f\"Prediction: {predictions[i]}\")\n",
        "            print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xHkw1y8z9cwV"
      },
      "outputs": [],
      "source": [
        "epochs = 1\n",
        "validation_callback = CustomCallback(val_dataset)\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data = val_dataset,\n",
        "    epochs = epochs,\n",
        "    callbacks = [validation_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsumIXuttj4e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}